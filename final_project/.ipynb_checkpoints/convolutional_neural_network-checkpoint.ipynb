{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import randint\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'chest-xray-pneumonia/chest_xray/train'\n",
    "test_dir =  'chest-xray-pneumonia/chest_xray/test'\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "\n",
    "for fileName in os.listdir(train_dir + \"/NORMAL\"): \n",
    "        img = cv2.imread(train_dir + \"/NORMAL/\" + fileName)\n",
    "        if img is not None:\n",
    "            Y.append(0)\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            X.append(img)\n",
    "    \n",
    "for fileName in os.listdir(train_dir + \"/PNEUMONIA\"): \n",
    "        img = cv2.imread(train_dir + \"/PNEUMONIA/\" + fileName)\n",
    "        if img is not None:\n",
    "            Y.append(1)\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            X.append(img)\n",
    "            \n",
    "for fileName in os.listdir(test_dir + \"/NORMAL\"): \n",
    "        img = cv2.imread(test_dir + \"/NORMAL/\" + fileName)\n",
    "        if img is not None:\n",
    "            Y.append(0)\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            X.append(img)\n",
    "    \n",
    "for fileName in os.listdir(test_dir + \"/PNEUMONIA\"): \n",
    "        img = cv2.imread(test_dir + \"/PNEUMONIA/\" + fileName)\n",
    "        if img is not None:\n",
    "            Y.append(1)\n",
    "            img = cv2.resize(img,(64,64))\n",
    "            X.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patient with Pneumonia:\")\n",
    "pneumonia = cv2.imread(test_dir + \"/PNEUMONIA/person15_virus_46.jpeg\")\n",
    "plt.axis('off')\n",
    "plt.imshow(pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patient without pneumonia:\")\n",
    "normal = cv2.imread(test_dir + \"/NORMAL/IM-0003-0001.jpeg\")\n",
    "plt.axis('off')\n",
    "plt.imshow(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "\n",
    "First we need to normalize the data. As pixels in images can only range from 0 to 255 we divide by 255 as it is the maximum value.\n",
    "\n",
    "Our labels can only take two values: 0 if the patient is not diagnosed with pneumonia, 1 if the patient is diagnosed with pneumonia. This values are loaded as strings so we need to transform them into integers. \n",
    "\n",
    "### Problem to solve \n",
    "\n",
    "Having said this, it is not hard to see that we are solving a binary classification problem. We will train a convolutional neural network to predict the probability of a patient of having pneumonia. Binary cross entropy will be used as our cost function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)/255\n",
    "X = (X - np.average(X,0))/np.std(X,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y = np.array(Y)\n",
    "Y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data \n",
    "\n",
    "We will partition our dataset into training, test and validation datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_validation, y_train, y_test_validation = train_test_split(X, Y,\n",
    "                                                    stratify=Y, \n",
    "                                                    test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test_validation, y_test_validation,\n",
    "                                                    stratify=y_test_validation, \n",
    "                                                    test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set: \", X_train.shape)\n",
    "print(\"Test set: \",X_test.shape)\n",
    "print(\"Validation set: \",X_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = X_train.shape[1]\n",
    "img_height = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1:\n",
    "* input layer with 32 filters of 3x3.\n",
    "* 2 hidden layers, each with 64 neurons.\n",
    "* Max pooling between each hidden layer.\n",
    "* adam optimizer.\n",
    "* data is fed in a single batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Convolution2D(32,(3,3), input_shape=(img_width,img_height,3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "###classification layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performed really well. However, training time took a while. This is due to the fact that a single batch was inserted for each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2:\n",
    "* 2 hidden layers, each with 64 neurons.\n",
    "* Max pooling between each hidden layer.\n",
    "* adam optimizer.\n",
    "* data is fed in mini batches of size 32.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.fit(X_train, y_train, epochs=5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2 = model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2 = model_2.evaluate(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden layers as intermediate representations\n",
    "\n",
    "Working with images is a great opportunity to visualize hidden layers of our convolutional network. These hidden layers represent the feature maps and how the convolutional neural network is training activations and thus decomposing the input images through these filters. \n",
    "\n",
    "First we need to define a model that has as output the hidden layers and representations. Then, we will pass an image to the model in order to plot the resulting activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers[:8]] \n",
    "activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a prediction using the activation model\n",
    "\n",
    "We will import an image to be used as an example for our activation model layers. \n",
    "\n",
    "<img src =\"chest-xray-pneumonia/chest_xray/test/PNEUMONIA/person15_virus_46.jpeg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(test_dir + \"/PNEUMONIA/person15_virus_46.jpeg\")\n",
    "image = cv2.resize(image,(64,64))\n",
    "image = image.reshape(1,64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activation_model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation =np.array(activations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = first_layer_activation.shape[3]\n",
    "i = 0\n",
    "while i < channels:\n",
    "    plt.matshow(first_layer_activation[0, :, :,i], cmap='viridis')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "second_layer_activation =np.array(activations[1])\n",
    "channels = second_layer_activation.shape[3]\n",
    "i = 1\n",
    "while i < channels:\n",
    "    plt.matshow(first_layer_activation[0, :, :,i], cmap='viridis')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5840, 64, 64, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
