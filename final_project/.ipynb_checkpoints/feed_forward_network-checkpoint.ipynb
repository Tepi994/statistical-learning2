{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "\n",
    "Implement a MLP Neural Network for predicting churn from a telecom dataset. \n",
    "\n",
    "#### Content\n",
    "\n",
    "Each row represents a customer, each column contains customer’s attributes described on the column Metadata.\n",
    "\n",
    "The data set includes information about:\n",
    "\n",
    "* Customers who left within the last month – the column is called Churn\n",
    "* Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "* Customer account information – how long they’ve been a customer, contract, payment method, paperless billing, monthly  charges, and total charges\n",
    "* Demographic info about customers – gender, age range, and if they have partners and dependents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns \n",
    "* **customerID**: Customer ID\n",
    "* **gender**: Whether the customer is a male or a female\n",
    "* **SeniorCitizen**: Whether the customer is a senior citizen or not (1, 0)\n",
    "* **Partner**: Whether the customer has a partner or not (Yes, No)\n",
    "* **Dependents**: Whether the customer has dependents or not (Yes, No)\n",
    "* **tenureNumber**: of months the customer has stayed with the company\n",
    "* **PhoneService**: Whether the customer has a phone service or not (Yes, No)\n",
    "* **MultipleLines**: Whether the customer has multiple lines or not (Yes, No, No phone service)\n",
    "* **InternetService**: Customer’s internet service provider (DSL, Fiber optic, No)\n",
    "* **OnlineSecurity**: Whether the customer has online security or not (Yes, No, No internet service)\n",
    "* **OnlineBackup**: Whether the customer has online backup or not (Yes, No, No internet service)\n",
    "* **DeviceProtection**: Whether the customer has device protection or not (Yes, No, No internet service)\n",
    "* **TechSupport**: Whether the customer has tech support or not (Yes, No, No internet service)\n",
    "* **StreamingTV**: Whether the customer has streaming TV or not (Yes, No, No internet service)\n",
    "* **StreamingMovies**: Whether the customer has streaming movies or not (Yes, No, No internet service)\n",
    "* **Contract**: The contract term of the customer (Month-to-month, One year, Two year)\n",
    "* **PaperlessBilling**: Whether the customer has paperless billing or not (Yes, No)\n",
    "* **PaymentMethod**: The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic))\n",
    "* **MonthlyCharges**: The amount charged to the customer monthly\n",
    "* **TotalCharges**: The total amount charged to the customer\n",
    "* **Churn**: Whether the customer churned or not (Yes or No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"telco-customer-churn\\churn_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick exploration of variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.162147</td>\n",
       "      <td>32.371149</td>\n",
       "      <td>64.761692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.368612</td>\n",
       "      <td>24.559481</td>\n",
       "      <td>30.090047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>35.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>70.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>89.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>118.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SeniorCitizen       tenure  MonthlyCharges\n",
       "count    7043.000000  7043.000000     7043.000000\n",
       "mean        0.162147    32.371149       64.761692\n",
       "std         0.368612    24.559481       30.090047\n",
       "min         0.000000     0.000000       18.250000\n",
       "25%         0.000000     9.000000       35.500000\n",
       "50%         0.000000    29.000000       70.350000\n",
       "75%         0.000000    55.000000       89.850000\n",
       "max         1.000000    72.000000      118.750000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      "customerID          7043 non-null object\n",
      "gender              7043 non-null object\n",
      "SeniorCitizen       7043 non-null int64\n",
      "Partner             7043 non-null object\n",
      "Dependents          7043 non-null object\n",
      "tenure              7043 non-null int64\n",
      "PhoneService        7043 non-null object\n",
      "MultipleLines       7043 non-null object\n",
      "InternetService     7043 non-null object\n",
      "OnlineSecurity      7043 non-null object\n",
      "OnlineBackup        7043 non-null object\n",
      "DeviceProtection    7043 non-null object\n",
      "TechSupport         7043 non-null object\n",
      "StreamingTV         7043 non-null object\n",
      "StreamingMovies     7043 non-null object\n",
      "Contract            7043 non-null object\n",
      "PaperlessBilling    7043 non-null object\n",
      "PaymentMethod       7043 non-null object\n",
      "MonthlyCharges      7043 non-null float64\n",
      "TotalCharges        7043 non-null object\n",
      "Churn               7043 non-null object\n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "To do's:\n",
    "\n",
    "* Encode text variables in order to feed them to a neural network.\n",
    "* Drop customerID as it is of no use \n",
    "* Deal with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'],errors='coerce')\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'],errors='coerce')\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(0.0)\n",
    "df[['TotalCharges', 'MonthlyCharges']]= scaler.fit_transform(df[['TotalCharges', 'MonthlyCharges']])\n",
    "df['MonthlyCharges'] = pd.to_numeric(df['MonthlyCharges'],errors='coerce')\n",
    "df['Churn_encoded'] = encoder.fit_transform(df['Churn'])\n",
    "df['gender_encoded'] = encoder.fit_transform(df['gender'])\n",
    "df['Partner_encoded'] = encoder.fit_transform(df['Partner'])\n",
    "df['Dependents_encoded'] = encoder.fit_transform(df['Dependents'])\n",
    "df['PhoneService_encoded'] = encoder.fit_transform(df['PhoneService'])\n",
    "df['PaperlessBilling_encoded'] = encoder.fit_transform(df['PaperlessBilling'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_creator(col_name,dataset):\n",
    "    dummies = pd.get_dummies(dataset[col_name]).rename(columns=lambda x: col_name + '_'+ str(x))\n",
    "    #dataset = pd.concat([dataset, dummies], axis=1)\n",
    "    return dummies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dummy_creator('TechSupport',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('MultipleLines',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('InternetService',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('OnlineSecurity',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('OnlineBackup',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('DeviceProtection',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('TechSupport',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('StreamingTV',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('StreamingMovies',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('Contract',df)], axis=1)\n",
    "df = pd.concat([df, dummy_creator('PaymentMethod',df)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropping not encoded columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges',\n",
       "       'Churn_encoded', 'gender_encoded', 'Partner_encoded',\n",
       "       'Dependents_encoded', 'PhoneService_encoded',\n",
       "       'PaperlessBilling_encoded', 'TechSupport_No',\n",
       "       'TechSupport_No internet service', 'TechSupport_Yes',\n",
       "       'MultipleLines_No', 'MultipleLines_No phone service',\n",
       "       'MultipleLines_Yes', 'InternetService_DSL',\n",
       "       'InternetService_Fiber optic', 'InternetService_No',\n",
       "       'OnlineSecurity_No', 'OnlineSecurity_No internet service',\n",
       "       'OnlineSecurity_Yes', 'OnlineBackup_No',\n",
       "       'OnlineBackup_No internet service', 'OnlineBackup_Yes',\n",
       "       'DeviceProtection_No', 'DeviceProtection_No internet service',\n",
       "       'DeviceProtection_Yes', 'TechSupport_No',\n",
       "       'TechSupport_No internet service', 'TechSupport_Yes', 'StreamingTV_No',\n",
       "       'StreamingTV_No internet service', 'StreamingTV_Yes',\n",
       "       'StreamingMovies_No', 'StreamingMovies_No internet service',\n",
       "       'StreamingMovies_Yes', 'Contract_Month-to-month', 'Contract_One year',\n",
       "       'Contract_Two year', 'PaymentMethod_Bank transfer (automatic)',\n",
       "       'PaymentMethod_Credit card (automatic)',\n",
       "       'PaymentMethod_Electronic check', 'PaymentMethod_Mailed check'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop= ['customerID','gender','Churn','Partner','Dependents','PhoneService','PaperlessBilling',\n",
    "          'TechSupport','MultipleLines','InternetService','OnlineSecurity',\n",
    "          'OnlineBackup','DeviceProtection','TechSupport',\n",
    "          'StreamingTV','StreamingMovies','Contract','PaymentMethod']\n",
    "\n",
    "df.drop(to_drop,axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(to_drop,axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn_encoded</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>Partner_encoded</th>\n",
       "      <th>Dependents_encoded</th>\n",
       "      <th>PhoneService_encoded</th>\n",
       "      <th>PaperlessBilling_encoded</th>\n",
       "      <th>...</th>\n",
       "      <th>StreamingMovies_No</th>\n",
       "      <th>StreamingMovies_No internet service</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.385075</td>\n",
       "      <td>0.217564</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.012453</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.239303</td>\n",
       "      <td>0.211951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521891</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeniorCitizen  tenure  MonthlyCharges  TotalCharges  Churn_encoded  \\\n",
       "0              0       1        0.115423      0.003437              0   \n",
       "1              0      34        0.385075      0.217564              0   \n",
       "2              0       2        0.354229      0.012453              1   \n",
       "3              0      45        0.239303      0.211951              0   \n",
       "4              0       2        0.521891      0.017462              1   \n",
       "\n",
       "   gender_encoded  Partner_encoded  Dependents_encoded  PhoneService_encoded  \\\n",
       "0               0                1                   0                     0   \n",
       "1               1                0                   0                     1   \n",
       "2               1                0                   0                     1   \n",
       "3               1                0                   0                     0   \n",
       "4               0                0                   0                     1   \n",
       "\n",
       "   PaperlessBilling_encoded  ...  StreamingMovies_No  \\\n",
       "0                         1  ...                   1   \n",
       "1                         0  ...                   1   \n",
       "2                         1  ...                   1   \n",
       "3                         0  ...                   1   \n",
       "4                         1  ...                   1   \n",
       "\n",
       "   StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   Contract_Month-to-month  Contract_One year  Contract_Two year  \\\n",
       "0                        1                  0                  0   \n",
       "1                        0                  1                  0   \n",
       "2                        1                  0                  0   \n",
       "3                        0                  1                  0   \n",
       "4                        1                  0                  0   \n",
       "\n",
       "   PaymentMethod_Bank transfer (automatic)  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation\n",
    "\n",
    "labels represent our variable to predict. df_features are our independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Churn_encoded']\n",
    "labels.head()\n",
    "df_features = df.drop(['Churn_encoded'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 43)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Partioning the datasets \n",
    "Data sets will be split in three: training, validation and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the datsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_validation, y_train, y_test_validation = train_test_split(df_features, labels,\n",
    "                                                    stratify=labels, \n",
    "                                                    test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the datsets\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_test_validation, y_test_validation,\n",
    "                                                    stratify=y_test_validation, \n",
    "                                                    test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1409, 43)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>gender_encoded</th>\n",
       "      <th>Partner_encoded</th>\n",
       "      <th>Dependents_encoded</th>\n",
       "      <th>PhoneService_encoded</th>\n",
       "      <th>PaperlessBilling_encoded</th>\n",
       "      <th>TechSupport_No</th>\n",
       "      <th>...</th>\n",
       "      <th>StreamingMovies_No</th>\n",
       "      <th>StreamingMovies_No internet service</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.313433</td>\n",
       "      <td>0.291953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5074</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.106082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.770149</td>\n",
       "      <td>0.432831</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.523881</td>\n",
       "      <td>0.226211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.563682</td>\n",
       "      <td>0.037047</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.463682</td>\n",
       "      <td>0.334861</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0.879602</td>\n",
       "      <td>0.595074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.757214</td>\n",
       "      <td>0.730178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.656219</td>\n",
       "      <td>0.685894</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.886567</td>\n",
       "      <td>0.589415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6720</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.655224</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.424876</td>\n",
       "      <td>0.523794</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.072637</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.246766</td>\n",
       "      <td>0.254243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.072637</td>\n",
       "      <td>0.053870</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269154</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.576119</td>\n",
       "      <td>0.567607</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4501</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.024378</td>\n",
       "      <td>0.087791</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.163184</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0.608458</td>\n",
       "      <td>0.593520</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.719900</td>\n",
       "      <td>0.386727</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.005473</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.611443</td>\n",
       "      <td>0.018999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.959204</td>\n",
       "      <td>0.959602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.157214</td>\n",
       "      <td>0.128264</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.816418</td>\n",
       "      <td>0.646469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2204</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.925871</td>\n",
       "      <td>0.861517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.061692</td>\n",
       "      <td>0.193626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5233</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.824876</td>\n",
       "      <td>0.097055</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>0.852697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.761692</td>\n",
       "      <td>0.180073</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.047761</td>\n",
       "      <td>0.144517</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.037877</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.111442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.804975</td>\n",
       "      <td>0.692019</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4899</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.654726</td>\n",
       "      <td>0.038406</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0.854229</td>\n",
       "      <td>0.857556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.305473</td>\n",
       "      <td>0.152416</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.826866</td>\n",
       "      <td>0.266799</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2676</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.020896</td>\n",
       "      <td>0.071084</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.472637</td>\n",
       "      <td>0.127948</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.657711</td>\n",
       "      <td>0.223154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.072637</td>\n",
       "      <td>0.058424</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578607</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.629353</td>\n",
       "      <td>0.639422</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.020116</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.362189</td>\n",
       "      <td>0.055528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>0.048648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.703980</td>\n",
       "      <td>0.679187</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.549751</td>\n",
       "      <td>0.008463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.645771</td>\n",
       "      <td>0.234093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.639303</td>\n",
       "      <td>0.481197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6201</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.621393</td>\n",
       "      <td>0.043156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.765174</td>\n",
       "      <td>0.779621</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.818408</td>\n",
       "      <td>0.299368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.673134</td>\n",
       "      <td>0.253207</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.637706</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.379602</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0.355721</td>\n",
       "      <td>0.280979</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4225 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SeniorCitizen  tenure  MonthlyCharges  TotalCharges  gender_encoded  \\\n",
       "4923              0      52        0.313433      0.291953               0   \n",
       "5074              0      49        0.011940      0.106082               0   \n",
       "2574              1      39        0.770149      0.432831               1   \n",
       "5121              0      29        0.523881      0.226211               1   \n",
       "4663              1       4        0.563682      0.037047               0   \n",
       "1431              0      43        0.463682      0.334861               0   \n",
       "2730              0      49        0.879602      0.595074               1   \n",
       "2614              0      67        0.757214      0.730178               0   \n",
       "2190              0      71        0.656219      0.685894               1   \n",
       "1927              0      47        0.886567      0.589415               1   \n",
       "6720              0      70        0.655224      0.688525               1   \n",
       "1352              0      72        0.424876      0.523794               1   \n",
       "2195              0      28        0.072637      0.077400               0   \n",
       "6966              0      50        0.246766      0.254243               1   \n",
       "1204              0      18        0.072637      0.053870               1   \n",
       "6064              0       1        0.269154      0.005216               1   \n",
       "4152              0      65        0.576119      0.567607               1   \n",
       "4501              0      39        0.024378      0.087791               0   \n",
       "1562              0       7        0.163184      0.028394               0   \n",
       "3779              1      66        0.608458      0.593520               1   \n",
       "6484              0      37        0.719900      0.386727               1   \n",
       "1654              0       1        0.005473      0.002165               1   \n",
       "4384              0       2        0.611443      0.018999               0   \n",
       "1135              1      72        0.959204      0.959602               0   \n",
       "3020              0      33        0.157214      0.128264               1   \n",
       "573               0      56        0.816418      0.646469               1   \n",
       "2204              0      67        0.925871      0.861517               1   \n",
       "2531              0      71        0.061692      0.193626               0   \n",
       "5233              0       8        0.824876      0.097055               0   \n",
       "202               0      71        0.868657      0.852697               1   \n",
       "...             ...     ...             ...           ...             ...   \n",
       "3954              1      17        0.761692      0.180073               1   \n",
       "4198              0      52        0.047761      0.144517               0   \n",
       "3680              0       9        0.222886      0.037877               1   \n",
       "1715              0      46        0.011443      0.111442               0   \n",
       "2877              0      61        0.804975      0.692019               0   \n",
       "4899              0       4        0.654726      0.038406               0   \n",
       "1606              1      72        0.854229      0.857556               1   \n",
       "3717              0      29        0.305473      0.152416               1   \n",
       "2673              0      22        0.826866      0.266799               1   \n",
       "2676              0      29        0.020896      0.071084               0   \n",
       "1220              0      17        0.472637      0.127948               1   \n",
       "1398              0      24        0.657711      0.223154               0   \n",
       "797               0      20        0.072637      0.058424               0   \n",
       "6231              1       1        0.578607      0.008797               0   \n",
       "1619              0      69        0.629353      0.639422               1   \n",
       "3941              0       7        0.019900      0.020116               1   \n",
       "77                0       8        0.362189      0.055528               0   \n",
       "1994              0      22        0.013433      0.048648               1   \n",
       "858               0      66        0.703980      0.679187               0   \n",
       "2911              0       1        0.549751      0.008463               0   \n",
       "1247              0      24        0.645771      0.234093               0   \n",
       "1121              0      50        0.639303      0.481197               0   \n",
       "6201              1       5        0.621393      0.043156               0   \n",
       "4767              0       1        0.015920      0.002286               1   \n",
       "1810              0      71        0.765174      0.779621               0   \n",
       "3838              0      26        0.818408      0.299368               0   \n",
       "1548              0      25        0.673134      0.253207               1   \n",
       "1196              0      66        0.666667      0.637706               1   \n",
       "906               0       4        0.379602      0.027041               1   \n",
       "3502              0      44        0.355721      0.280979               1   \n",
       "\n",
       "      Partner_encoded  Dependents_encoded  PhoneService_encoded  \\\n",
       "4923                0                   0                     1   \n",
       "5074                0                   1                     1   \n",
       "2574                0                   0                     1   \n",
       "5121                0                   0                     1   \n",
       "4663                0                   0                     1   \n",
       "1431                1                   0                     1   \n",
       "2730                0                   0                     1   \n",
       "2614                1                   1                     1   \n",
       "2190                1                   0                     1   \n",
       "1927                1                   1                     1   \n",
       "6720                1                   1                     1   \n",
       "1352                1                   1                     0   \n",
       "2195                1                   0                     1   \n",
       "6966                0                   1                     0   \n",
       "1204                1                   1                     0   \n",
       "6064                0                   0                     0   \n",
       "4152                1                   0                     1   \n",
       "4501                0                   0                     1   \n",
       "1562                1                   1                     0   \n",
       "3779                1                   1                     1   \n",
       "6484                0                   0                     1   \n",
       "1654                1                   1                     1   \n",
       "4384                1                   0                     1   \n",
       "1135                1                   0                     1   \n",
       "3020                0                   1                     0   \n",
       "573                 1                   0                     1   \n",
       "2204                1                   1                     1   \n",
       "2531                1                   0                     1   \n",
       "5233                1                   0                     1   \n",
       "202                 1                   1                     1   \n",
       "...               ...                 ...                   ...   \n",
       "3954                1                   0                     1   \n",
       "4198                1                   1                     1   \n",
       "3680                1                   0                     0   \n",
       "1715                1                   1                     1   \n",
       "2877                1                   1                     1   \n",
       "4899                0                   1                     1   \n",
       "1606                1                   1                     1   \n",
       "3717                0                   0                     1   \n",
       "2673                0                   0                     1   \n",
       "2676                0                   0                     1   \n",
       "1220                0                   0                     1   \n",
       "1398                0                   0                     1   \n",
       "797                 1                   1                     1   \n",
       "6231                1                   0                     1   \n",
       "1619                0                   0                     1   \n",
       "3941                1                   1                     1   \n",
       "77                  1                   1                     1   \n",
       "1994                0                   0                     1   \n",
       "858                 1                   0                     1   \n",
       "2911                0                   0                     1   \n",
       "1247                1                   1                     1   \n",
       "1121                0                   0                     1   \n",
       "6201                0                   0                     1   \n",
       "4767                1                   1                     1   \n",
       "1810                1                   1                     1   \n",
       "3838                0                   0                     1   \n",
       "1548                1                   1                     1   \n",
       "1196                1                   0                     1   \n",
       "906                 0                   0                     1   \n",
       "3502                0                   0                     0   \n",
       "\n",
       "      PaperlessBilling_encoded  TechSupport_No  ...  StreamingMovies_No  \\\n",
       "4923                         1               1  ...                   1   \n",
       "5074                         0               0  ...                   0   \n",
       "2574                         1               1  ...                   0   \n",
       "5121                         0               1  ...                   0   \n",
       "4663                         1               1  ...                   1   \n",
       "1431                         1               0  ...                   1   \n",
       "2730                         1               0  ...                   0   \n",
       "2614                         1               0  ...                   0   \n",
       "2190                         0               0  ...                   0   \n",
       "1927                         1               0  ...                   0   \n",
       "6720                         1               0  ...                   0   \n",
       "1352                         0               0  ...                   0   \n",
       "2195                         0               0  ...                   0   \n",
       "6966                         1               1  ...                   1   \n",
       "1204                         0               1  ...                   1   \n",
       "6064                         1               1  ...                   0   \n",
       "4152                         0               0  ...                   0   \n",
       "4501                         0               0  ...                   0   \n",
       "1562                         0               0  ...                   1   \n",
       "3779                         0               0  ...                   1   \n",
       "6484                         1               0  ...                   0   \n",
       "1654                         0               0  ...                   0   \n",
       "4384                         0               1  ...                   1   \n",
       "1135                         1               0  ...                   0   \n",
       "3020                         0               0  ...                   1   \n",
       "573                          0               1  ...                   0   \n",
       "2204                         1               1  ...                   0   \n",
       "2531                         1               0  ...                   0   \n",
       "5233                         0               1  ...                   0   \n",
       "202                          0               1  ...                   0   \n",
       "...                        ...             ...  ...                 ...   \n",
       "3954                         1               1  ...                   0   \n",
       "4198                         0               0  ...                   0   \n",
       "3680                         0               0  ...                   1   \n",
       "1715                         0               0  ...                   0   \n",
       "2877                         1               1  ...                   0   \n",
       "4899                         0               1  ...                   1   \n",
       "1606                         1               0  ...                   0   \n",
       "3717                         0               1  ...                   1   \n",
       "2673                         1               1  ...                   0   \n",
       "2676                         0               0  ...                   0   \n",
       "1220                         0               1  ...                   0   \n",
       "1398                         1               0  ...                   1   \n",
       "797                          1               0  ...                   0   \n",
       "6231                         1               1  ...                   1   \n",
       "1619                         1               0  ...                   0   \n",
       "3941                         1               0  ...                   0   \n",
       "77                           0               1  ...                   1   \n",
       "1994                         0               0  ...                   0   \n",
       "858                          0               0  ...                   1   \n",
       "2911                         0               1  ...                   1   \n",
       "1247                         0               1  ...                   1   \n",
       "1121                         1               0  ...                   0   \n",
       "6201                         0               1  ...                   1   \n",
       "4767                         0               0  ...                   0   \n",
       "1810                         1               0  ...                   1   \n",
       "3838                         1               1  ...                   0   \n",
       "1548                         0               0  ...                   1   \n",
       "1196                         0               0  ...                   0   \n",
       "906                          1               1  ...                   1   \n",
       "3502                         1               1  ...                   0   \n",
       "\n",
       "      StreamingMovies_No internet service  StreamingMovies_Yes  \\\n",
       "4923                                    0                    0   \n",
       "5074                                    1                    0   \n",
       "2574                                    0                    1   \n",
       "5121                                    0                    1   \n",
       "4663                                    0                    0   \n",
       "1431                                    0                    0   \n",
       "2730                                    0                    1   \n",
       "2614                                    0                    1   \n",
       "2190                                    0                    1   \n",
       "1927                                    0                    1   \n",
       "6720                                    0                    1   \n",
       "1352                                    0                    1   \n",
       "2195                                    1                    0   \n",
       "6966                                    0                    0   \n",
       "1204                                    0                    0   \n",
       "6064                                    0                    1   \n",
       "4152                                    0                    1   \n",
       "4501                                    1                    0   \n",
       "1562                                    0                    0   \n",
       "3779                                    0                    0   \n",
       "6484                                    0                    1   \n",
       "1654                                    1                    0   \n",
       "4384                                    0                    0   \n",
       "1135                                    0                    1   \n",
       "3020                                    0                    0   \n",
       "573                                     0                    1   \n",
       "2204                                    0                    1   \n",
       "2531                                    1                    0   \n",
       "5233                                    0                    1   \n",
       "202                                     0                    1   \n",
       "...                                   ...                  ...   \n",
       "3954                                    0                    1   \n",
       "4198                                    1                    0   \n",
       "3680                                    0                    0   \n",
       "1715                                    1                    0   \n",
       "2877                                    0                    1   \n",
       "4899                                    0                    0   \n",
       "1606                                    0                    1   \n",
       "3717                                    0                    0   \n",
       "2673                                    0                    1   \n",
       "2676                                    1                    0   \n",
       "1220                                    0                    1   \n",
       "1398                                    0                    0   \n",
       "797                                     1                    0   \n",
       "6231                                    0                    0   \n",
       "1619                                    0                    1   \n",
       "3941                                    1                    0   \n",
       "77                                      0                    0   \n",
       "1994                                    1                    0   \n",
       "858                                     0                    0   \n",
       "2911                                    0                    0   \n",
       "1247                                    0                    0   \n",
       "1121                                    0                    1   \n",
       "6201                                    0                    0   \n",
       "4767                                    1                    0   \n",
       "1810                                    0                    0   \n",
       "3838                                    0                    1   \n",
       "1548                                    0                    0   \n",
       "1196                                    0                    1   \n",
       "906                                     0                    0   \n",
       "3502                                    0                    1   \n",
       "\n",
       "      Contract_Month-to-month  Contract_One year  Contract_Two year  \\\n",
       "4923                        1                  0                  0   \n",
       "5074                        0                  1                  0   \n",
       "2574                        1                  0                  0   \n",
       "5121                        0                  1                  0   \n",
       "4663                        1                  0                  0   \n",
       "1431                        0                  1                  0   \n",
       "2730                        0                  1                  0   \n",
       "2614                        0                  1                  0   \n",
       "2190                        0                  0                  1   \n",
       "1927                        1                  0                  0   \n",
       "6720                        0                  0                  1   \n",
       "1352                        0                  0                  1   \n",
       "2195                        0                  1                  0   \n",
       "6966                        0                  1                  0   \n",
       "1204                        1                  0                  0   \n",
       "6064                        1                  0                  0   \n",
       "4152                        0                  0                  1   \n",
       "4501                        0                  0                  1   \n",
       "1562                        1                  0                  0   \n",
       "3779                        0                  0                  1   \n",
       "6484                        0                  1                  0   \n",
       "1654                        0                  1                  0   \n",
       "4384                        1                  0                  0   \n",
       "1135                        0                  0                  1   \n",
       "3020                        0                  1                  0   \n",
       "573                         0                  1                  0   \n",
       "2204                        0                  1                  0   \n",
       "2531                        0                  0                  1   \n",
       "5233                        1                  0                  0   \n",
       "202                         0                  0                  1   \n",
       "...                       ...                ...                ...   \n",
       "3954                        1                  0                  0   \n",
       "4198                        0                  0                  1   \n",
       "3680                        1                  0                  0   \n",
       "1715                        0                  0                  1   \n",
       "2877                        1                  0                  0   \n",
       "4899                        1                  0                  0   \n",
       "1606                        0                  0                  1   \n",
       "3717                        1                  0                  0   \n",
       "2673                        1                  0                  0   \n",
       "2676                        0                  1                  0   \n",
       "1220                        1                  0                  0   \n",
       "1398                        1                  0                  0   \n",
       "797                         1                  0                  0   \n",
       "6231                        1                  0                  0   \n",
       "1619                        0                  0                  1   \n",
       "3941                        1                  0                  0   \n",
       "77                          1                  0                  0   \n",
       "1994                        0                  1                  0   \n",
       "858                         0                  1                  0   \n",
       "2911                        1                  0                  0   \n",
       "1247                        0                  1                  0   \n",
       "1121                        0                  1                  0   \n",
       "6201                        1                  0                  0   \n",
       "4767                        0                  1                  0   \n",
       "1810                        0                  1                  0   \n",
       "3838                        1                  0                  0   \n",
       "1548                        1                  0                  0   \n",
       "1196                        0                  0                  1   \n",
       "906                         1                  0                  0   \n",
       "3502                        0                  1                  0   \n",
       "\n",
       "      PaymentMethod_Bank transfer (automatic)  \\\n",
       "4923                                        1   \n",
       "5074                                        0   \n",
       "2574                                        1   \n",
       "5121                                        0   \n",
       "4663                                        0   \n",
       "1431                                        1   \n",
       "2730                                        1   \n",
       "2614                                        0   \n",
       "2190                                        0   \n",
       "1927                                        1   \n",
       "6720                                        0   \n",
       "1352                                        1   \n",
       "2195                                        0   \n",
       "6966                                        1   \n",
       "1204                                        0   \n",
       "6064                                        0   \n",
       "4152                                        1   \n",
       "4501                                        0   \n",
       "1562                                        0   \n",
       "3779                                        0   \n",
       "6484                                        1   \n",
       "1654                                        0   \n",
       "4384                                        1   \n",
       "1135                                        1   \n",
       "3020                                        0   \n",
       "573                                         0   \n",
       "2204                                        0   \n",
       "2531                                        0   \n",
       "5233                                        0   \n",
       "202                                         0   \n",
       "...                                       ...   \n",
       "3954                                        0   \n",
       "4198                                        0   \n",
       "3680                                        0   \n",
       "1715                                        0   \n",
       "2877                                        0   \n",
       "4899                                        1   \n",
       "1606                                        0   \n",
       "3717                                        1   \n",
       "2673                                        1   \n",
       "2676                                        0   \n",
       "1220                                        1   \n",
       "1398                                        0   \n",
       "797                                         1   \n",
       "6231                                        0   \n",
       "1619                                        0   \n",
       "3941                                        1   \n",
       "77                                          0   \n",
       "1994                                        0   \n",
       "858                                         0   \n",
       "2911                                        1   \n",
       "1247                                        1   \n",
       "1121                                        0   \n",
       "6201                                        0   \n",
       "4767                                        0   \n",
       "1810                                        0   \n",
       "3838                                        1   \n",
       "1548                                        0   \n",
       "1196                                        0   \n",
       "906                                         0   \n",
       "3502                                        0   \n",
       "\n",
       "      PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check  \\\n",
       "4923                                      0                               0   \n",
       "5074                                      1                               0   \n",
       "2574                                      0                               0   \n",
       "5121                                      1                               0   \n",
       "4663                                      0                               1   \n",
       "1431                                      0                               0   \n",
       "2730                                      0                               0   \n",
       "2614                                      1                               0   \n",
       "2190                                      1                               0   \n",
       "1927                                      0                               0   \n",
       "6720                                      0                               1   \n",
       "1352                                      0                               0   \n",
       "2195                                      0                               0   \n",
       "6966                                      0                               0   \n",
       "1204                                      1                               0   \n",
       "6064                                      0                               0   \n",
       "4152                                      0                               0   \n",
       "4501                                      1                               0   \n",
       "1562                                      0                               0   \n",
       "3779                                      1                               0   \n",
       "6484                                      0                               0   \n",
       "1654                                      0                               0   \n",
       "4384                                      0                               0   \n",
       "1135                                      0                               0   \n",
       "3020                                      1                               0   \n",
       "573                                       1                               0   \n",
       "2204                                      0                               1   \n",
       "2531                                      1                               0   \n",
       "5233                                      0                               1   \n",
       "202                                       0                               1   \n",
       "...                                     ...                             ...   \n",
       "3954                                      0                               1   \n",
       "4198                                      0                               0   \n",
       "3680                                      0                               0   \n",
       "1715                                      0                               0   \n",
       "2877                                      0                               1   \n",
       "4899                                      0                               0   \n",
       "1606                                      1                               0   \n",
       "3717                                      0                               0   \n",
       "2673                                      0                               0   \n",
       "2676                                      0                               0   \n",
       "1220                                      0                               0   \n",
       "1398                                      0                               1   \n",
       "797                                       0                               0   \n",
       "6231                                      0                               0   \n",
       "1619                                      1                               0   \n",
       "3941                                      0                               0   \n",
       "77                                        0                               0   \n",
       "1994                                      0                               0   \n",
       "858                                       0                               1   \n",
       "2911                                      0                               0   \n",
       "1247                                      0                               0   \n",
       "1121                                      1                               0   \n",
       "6201                                      0                               1   \n",
       "4767                                      1                               0   \n",
       "1810                                      1                               0   \n",
       "3838                                      0                               0   \n",
       "1548                                      0                               1   \n",
       "1196                                      0                               1   \n",
       "906                                       0                               1   \n",
       "3502                                      0                               1   \n",
       "\n",
       "      PaymentMethod_Mailed check  \n",
       "4923                           0  \n",
       "5074                           0  \n",
       "2574                           0  \n",
       "5121                           0  \n",
       "4663                           0  \n",
       "1431                           0  \n",
       "2730                           0  \n",
       "2614                           0  \n",
       "2190                           0  \n",
       "1927                           0  \n",
       "6720                           0  \n",
       "1352                           0  \n",
       "2195                           1  \n",
       "6966                           0  \n",
       "1204                           0  \n",
       "6064                           1  \n",
       "4152                           0  \n",
       "4501                           0  \n",
       "1562                           1  \n",
       "3779                           0  \n",
       "6484                           0  \n",
       "1654                           1  \n",
       "4384                           0  \n",
       "1135                           0  \n",
       "3020                           0  \n",
       "573                            0  \n",
       "2204                           0  \n",
       "2531                           0  \n",
       "5233                           0  \n",
       "202                            0  \n",
       "...                          ...  \n",
       "3954                           0  \n",
       "4198                           1  \n",
       "3680                           1  \n",
       "1715                           1  \n",
       "2877                           0  \n",
       "4899                           0  \n",
       "1606                           0  \n",
       "3717                           0  \n",
       "2673                           0  \n",
       "2676                           1  \n",
       "1220                           0  \n",
       "1398                           0  \n",
       "797                            0  \n",
       "6231                           1  \n",
       "1619                           0  \n",
       "3941                           0  \n",
       "77                             1  \n",
       "1994                           1  \n",
       "858                            0  \n",
       "2911                           0  \n",
       "1247                           0  \n",
       "1121                           0  \n",
       "6201                           0  \n",
       "4767                           0  \n",
       "1810                           0  \n",
       "3838                           0  \n",
       "1548                           0  \n",
       "1196                           0  \n",
       "906                            0  \n",
       "3502                           0  \n",
       "\n",
       "[4225 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:\n",
    "* First layer with 43 input features combined with a dropout layer.\n",
    "* Second layer with 64 neurons combined with a dropout layer.\n",
    "* Output layer with sigmoid activation \n",
    "* rmsprop optimizer\n",
    "* cross entropy as loss function \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a ModelCheckpoint \n",
    "\n",
    "Model checkpoints will be implemented for every experiment. This is done in order to preserve the best performing models and to checkpoint our data to avoid data loss.\n",
    "\n",
    "* ModelCheckpoint will save the best model based on validation loss while training. \n",
    "* EarlyStopping will stop training when validation loss is no longer decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks_1 = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(('mlp/experiment_1/model.h5'), save_best_only=True, \n",
    "                             save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jctep\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\jctep\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(layers.Dense(64, input_dim=43, activation='sigmoid'))\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "model_1.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_1.add(layers.Dropout(0.5))\n",
    "model_1.add(layers.Dense(1, activation='sigmoid'))\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_1.compile(loss='binary_crossentropy',\n",
    "              #optimizer = tf.train.AdamOptimizer(0.001),\n",
    "              optimizer='rmsprop',\n",
    "              #optimizer = sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4225 samples, validate on 1409 samples\n",
      "Epoch 1/100\n",
      "4225/4225 [==============================] - 1s 172us/sample - loss: 0.4285 - acc: 0.7898 - val_loss: 0.3979 - val_acc: 0.8126\n",
      "Epoch 2/100\n",
      "4225/4225 [==============================] - 1s 193us/sample - loss: 0.4276 - acc: 0.7953 - val_loss: 0.3962 - val_acc: 0.8098\n",
      "Epoch 3/100\n",
      "4225/4225 [==============================] - 1s 153us/sample - loss: 0.4312 - acc: 0.7983 - val_loss: 0.3968 - val_acc: 0.8084\n",
      "Epoch 4/100\n",
      "4225/4225 [==============================] - 1s 170us/sample - loss: 0.4275 - acc: 0.7929 - val_loss: 0.3954 - val_acc: 0.8105\n",
      "Epoch 5/100\n",
      "4225/4225 [==============================] - 1s 187us/sample - loss: 0.4299 - acc: 0.7979 - val_loss: 0.3945 - val_acc: 0.8126\n",
      "Epoch 6/100\n",
      "4225/4225 [==============================] - 1s 148us/sample - loss: 0.4255 - acc: 0.8009 - val_loss: 0.3957 - val_acc: 0.8105\n",
      "Epoch 7/100\n",
      "4225/4225 [==============================] - 1s 206us/sample - loss: 0.4273 - acc: 0.7960 - val_loss: 0.3937 - val_acc: 0.8126\n",
      "Epoch 8/100\n",
      "4225/4225 [==============================] - 1s 140us/sample - loss: 0.4284 - acc: 0.7927 - val_loss: 0.3941 - val_acc: 0.8119\n",
      "Epoch 9/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.4250 - acc: 0.7981 - val_loss: 0.3938 - val_acc: 0.8133\n",
      "Epoch 10/100\n",
      "4225/4225 [==============================] - 1s 140us/sample - loss: 0.4271 - acc: 0.7964 - val_loss: 0.3940 - val_acc: 0.8126\n",
      "Epoch 11/100\n",
      "4225/4225 [==============================] - 1s 172us/sample - loss: 0.4297 - acc: 0.7986 - val_loss: 0.3935 - val_acc: 0.8105\n",
      "Epoch 12/100\n",
      "4225/4225 [==============================] - 1s 201us/sample - loss: 0.4263 - acc: 0.7993 - val_loss: 0.3933 - val_acc: 0.8112\n",
      "Epoch 13/100\n",
      "4225/4225 [==============================] - 1s 150us/sample - loss: 0.4258 - acc: 0.7964 - val_loss: 0.3934 - val_acc: 0.8155\n",
      "Epoch 14/100\n",
      "4225/4225 [==============================] - 1s 184us/sample - loss: 0.4246 - acc: 0.7922 - val_loss: 0.3927 - val_acc: 0.8126\n",
      "Epoch 15/100\n",
      "4225/4225 [==============================] - 1s 144us/sample - loss: 0.4261 - acc: 0.8005 - val_loss: 0.3930 - val_acc: 0.8091\n",
      "Epoch 16/100\n",
      "4225/4225 [==============================] - 1s 176us/sample - loss: 0.4245 - acc: 0.7995 - val_loss: 0.3927 - val_acc: 0.8112\n",
      "Epoch 17/100\n",
      "4225/4225 [==============================] - 1s 152us/sample - loss: 0.4244 - acc: 0.8059 - val_loss: 0.3943 - val_acc: 0.8155\n",
      "Epoch 18/100\n",
      "4225/4225 [==============================] - 1s 147us/sample - loss: 0.4254 - acc: 0.7969 - val_loss: 0.3928 - val_acc: 0.8133\n",
      "Epoch 19/100\n",
      "4225/4225 [==============================] - 1s 148us/sample - loss: 0.4270 - acc: 0.7998 - val_loss: 0.3936 - val_acc: 0.8077\n",
      "1409/1409 [==============================] - 0s 62us/sample - loss: 0.4152 - acc: 0.8062\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "model_1.fit(X_train, y_train,epochs=epochs,batch_size=batch_size, \n",
    "            callbacks = callbacks_1, validation_data=(X_validation, y_validation))\n",
    "#model_1.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks =callbacks_1)\n",
    "score_1 = model_1.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though 100 epochs where given as a hyperparameter, our model stopped at the 19th iterations. This is due to the fact that our validation loss did not improve on the last 5 iterations. \n",
    "training accuracy, validation accuracy are all very similar. This means that we have a well fitted and generalized model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 \n",
    "* First layer with 43 input features combined with a dropout layer.\n",
    "* Second layer with 64 neurons combined with a dropout layer.\n",
    "* Output layer with sigmoid activation \n",
    "* Adam optimizer\n",
    "* cross entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_2 = [EarlyStopping(monitor='val_acc', patience=10),\n",
    "             ModelCheckpoint(('mlp/experiment_2/model.h5'), save_best_only=True, \n",
    "                             save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.Sequential()\n",
    "model_2.add(layers.Dense(64, input_dim=43, activation='sigmoid'))\n",
    "model_2.add(layers.Dropout(0.5))\n",
    "model_2.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_2.add(layers.Dropout(0.5))\n",
    "model_2.add(layers.Dense(1, activation='sigmoid'))\n",
    "#sgd = tf.keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_2.compile(loss='binary_crossentropy',\n",
    "              optimizer = tf.train.AdamOptimizer(0.01),\n",
    "              #optimizer = sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4225 samples, validate on 1409 samples\n",
      "Epoch 1/100\n",
      "4225/4225 [==============================] - 0s 81us/sample - loss: 0.6007 - acc: 0.7148 - val_loss: 0.4658 - val_acc: 0.7913\n",
      "Epoch 2/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4801 - acc: 0.7680 - val_loss: 0.4172 - val_acc: 0.8070\n",
      "Epoch 3/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4599 - acc: 0.7844 - val_loss: 0.4064 - val_acc: 0.8105\n",
      "Epoch 4/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4501 - acc: 0.7837 - val_loss: 0.4041 - val_acc: 0.8098\n",
      "Epoch 5/100\n",
      "4225/4225 [==============================] - 0s 20us/sample - loss: 0.4388 - acc: 0.7920 - val_loss: 0.4041 - val_acc: 0.8126\n",
      "Epoch 6/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4423 - acc: 0.7962 - val_loss: 0.4038 - val_acc: 0.8077\n",
      "Epoch 7/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4345 - acc: 0.7972 - val_loss: 0.4009 - val_acc: 0.8098\n",
      "Epoch 8/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4293 - acc: 0.7974 - val_loss: 0.3974 - val_acc: 0.8084\n",
      "Epoch 9/100\n",
      "4225/4225 [==============================] - 0s 26us/sample - loss: 0.4260 - acc: 0.7964 - val_loss: 0.3985 - val_acc: 0.8119\n",
      "Epoch 10/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4288 - acc: 0.7972 - val_loss: 0.3982 - val_acc: 0.8098\n",
      "Epoch 11/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4311 - acc: 0.8002 - val_loss: 0.3973 - val_acc: 0.8077\n",
      "Epoch 12/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4294 - acc: 0.8005 - val_loss: 0.3978 - val_acc: 0.8091\n",
      "Epoch 13/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4296 - acc: 0.7948 - val_loss: 0.3959 - val_acc: 0.8055\n",
      "Epoch 14/100\n",
      "4225/4225 [==============================] - 0s 20us/sample - loss: 0.4288 - acc: 0.7986 - val_loss: 0.3963 - val_acc: 0.8084\n",
      "Epoch 15/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4253 - acc: 0.8009 - val_loss: 0.3955 - val_acc: 0.8148\n",
      "Epoch 16/100\n",
      "4225/4225 [==============================] - 0s 20us/sample - loss: 0.4240 - acc: 0.8052 - val_loss: 0.3960 - val_acc: 0.8098\n",
      "Epoch 17/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4231 - acc: 0.8028 - val_loss: 0.3971 - val_acc: 0.8141\n",
      "Epoch 18/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4212 - acc: 0.8017 - val_loss: 0.3942 - val_acc: 0.8148\n",
      "Epoch 19/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4229 - acc: 0.7969 - val_loss: 0.3978 - val_acc: 0.8062\n",
      "Epoch 20/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4230 - acc: 0.7993 - val_loss: 0.3961 - val_acc: 0.8155\n",
      "Epoch 21/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4202 - acc: 0.8054 - val_loss: 0.3947 - val_acc: 0.8141\n",
      "Epoch 22/100\n",
      "4225/4225 [==============================] - 0s 20us/sample - loss: 0.4210 - acc: 0.7950 - val_loss: 0.3940 - val_acc: 0.8133\n",
      "Epoch 23/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4234 - acc: 0.7991 - val_loss: 0.3964 - val_acc: 0.8084\n",
      "Epoch 24/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4247 - acc: 0.8045 - val_loss: 0.3954 - val_acc: 0.8055\n",
      "Epoch 25/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4193 - acc: 0.8017 - val_loss: 0.3943 - val_acc: 0.8169\n",
      "Epoch 26/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4187 - acc: 0.8009 - val_loss: 0.3945 - val_acc: 0.8077\n",
      "Epoch 27/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4175 - acc: 0.8059 - val_loss: 0.3954 - val_acc: 0.8183\n",
      "Epoch 28/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4171 - acc: 0.8059 - val_loss: 0.3956 - val_acc: 0.8141\n",
      "Epoch 29/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4213 - acc: 0.8028 - val_loss: 0.3953 - val_acc: 0.8183\n",
      "Epoch 30/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4180 - acc: 0.8026 - val_loss: 0.3990 - val_acc: 0.8141\n",
      "Epoch 31/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4213 - acc: 0.8019 - val_loss: 0.3958 - val_acc: 0.8133\n",
      "Epoch 32/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4173 - acc: 0.8059 - val_loss: 0.3998 - val_acc: 0.8141\n",
      "Epoch 33/100\n",
      "4225/4225 [==============================] - 0s 20us/sample - loss: 0.4169 - acc: 0.8002 - val_loss: 0.3969 - val_acc: 0.8176\n",
      "Epoch 34/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4168 - acc: 0.8028 - val_loss: 0.3984 - val_acc: 0.8098\n",
      "Epoch 35/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4189 - acc: 0.8031 - val_loss: 0.3957 - val_acc: 0.8112\n",
      "Epoch 36/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4164 - acc: 0.8036 - val_loss: 0.3944 - val_acc: 0.8077\n",
      "Epoch 37/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.4185 - acc: 0.8036 - val_loss: 0.3938 - val_acc: 0.8133\n",
      "1409/1409 [==============================] - 0s 13us/sample - loss: 0.4197 - acc: 0.8034\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "model_2.fit(X_train, y_train,epochs=epochs,batch_size=batch_size, \n",
    "            callbacks = callbacks_2, validation_data=(X_validation, y_validation))\n",
    "#model_1.fit(X_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, callbacks =callbacks_1)\n",
    "score_2 = model_2.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4225/4225 [==============================] - 2s 369us/sample - loss: 3.3650 - acc: 0.6888\n",
      "Epoch 2/100\n",
      "4225/4225 [==============================] - 1s 132us/sample - loss: 2.8219 - acc: 0.7122\n",
      "Epoch 3/100\n",
      "4225/4225 [==============================] - 1s 135us/sample - loss: 2.7033 - acc: 0.7385\n",
      "Epoch 4/100\n",
      "4225/4225 [==============================] - 1s 134us/sample - loss: 2.4913 - acc: 0.7517\n",
      "Epoch 5/100\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 2.3681 - acc: 0.7640\n",
      "Epoch 6/100\n",
      "4225/4225 [==============================] - 1s 151us/sample - loss: 2.2936 - acc: 0.7560\n",
      "Epoch 7/100\n",
      "4225/4225 [==============================] - 1s 170us/sample - loss: 2.2712 - acc: 0.7636\n",
      "Epoch 8/100\n",
      "4225/4225 [==============================] - 1s 159us/sample - loss: 2.1631 - acc: 0.7574\n",
      "Epoch 9/100\n",
      "4225/4225 [==============================] - 1s 165us/sample - loss: 1.9356 - acc: 0.7673\n",
      "Epoch 10/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 1.6956 - acc: 0.7576\n",
      "Epoch 11/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 1.3788 - acc: 0.7595\n",
      "Epoch 12/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 1.0833 - acc: 0.7605\n",
      "Epoch 13/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 0.8861 - acc: 0.7671\n",
      "Epoch 14/100\n",
      "4225/4225 [==============================] - 1s 141us/sample - loss: 0.7166 - acc: 0.7636\n",
      "Epoch 15/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.6608 - acc: 0.7697\n",
      "Epoch 16/100\n",
      "4225/4225 [==============================] - 1s 144us/sample - loss: 0.6082 - acc: 0.7796\n",
      "Epoch 17/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.5857 - acc: 0.7775\n",
      "Epoch 18/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 0.5884 - acc: 0.7867\n",
      "Epoch 19/100\n",
      "4225/4225 [==============================] - 1s 140us/sample - loss: 0.5858 - acc: 0.7830\n",
      "Epoch 20/100\n",
      "4225/4225 [==============================] - 1s 139us/sample - loss: 0.6022 - acc: 0.7751s - loss: 0.7695 - \n",
      "Epoch 21/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.5281 - acc: 0.7832\n",
      "Epoch 22/100\n",
      "4225/4225 [==============================] - 1s 144us/sample - loss: 0.5422 - acc: 0.7898\n",
      "Epoch 23/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 0.5535 - acc: 0.7875\n",
      "Epoch 24/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 0.5863 - acc: 0.7882\n",
      "Epoch 25/100\n",
      "4225/4225 [==============================] - 1s 141us/sample - loss: 0.5719 - acc: 0.7891\n",
      "Epoch 26/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 0.5611 - acc: 0.7856\n",
      "Epoch 27/100\n",
      "4225/4225 [==============================] - 1s 145us/sample - loss: 0.5167 - acc: 0.7872\n",
      "Epoch 28/100\n",
      "4225/4225 [==============================] - 1s 140us/sample - loss: 0.5369 - acc: 0.7927\n",
      "Epoch 29/100\n",
      "4225/4225 [==============================] - 1s 138us/sample - loss: 0.5386 - acc: 0.7901\n",
      "Epoch 30/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.5276 - acc: 0.7865\n",
      "Epoch 31/100\n",
      "4225/4225 [==============================] - 1s 144us/sample - loss: 0.5131 - acc: 0.7853\n",
      "Epoch 32/100\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.5546 - acc: 0.7924\n",
      "Epoch 33/100\n",
      "4225/4225 [==============================] - 1s 147us/sample - loss: 0.5404 - acc: 0.7924\n",
      "Epoch 34/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 0.5538 - acc: 0.7917\n",
      "Epoch 35/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 0.5267 - acc: 0.7920\n",
      "Epoch 36/100\n",
      "4225/4225 [==============================] - 1s 145us/sample - loss: 0.5172 - acc: 0.7931\n",
      "Epoch 37/100\n",
      "4225/4225 [==============================] - 1s 144us/sample - loss: 0.5265 - acc: 0.7901\n",
      "Epoch 38/100\n",
      "4225/4225 [==============================] - 1s 145us/sample - loss: 0.5261 - acc: 0.7946\n",
      "Epoch 39/100\n",
      "4225/4225 [==============================] - 1s 148us/sample - loss: 0.5233 - acc: 0.7908\n",
      "Epoch 40/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 0.5224 - acc: 0.7915\n",
      "Epoch 41/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 0.5299 - acc: 0.7917\n",
      "Epoch 42/100\n",
      "4225/4225 [==============================] - 1s 147us/sample - loss: 0.5631 - acc: 0.7931\n",
      "Epoch 43/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 0.5412 - acc: 0.7955\n",
      "Epoch 44/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 0.6094 - acc: 0.7993\n",
      "Epoch 45/100\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.5690 - acc: 0.7972\n",
      "Epoch 46/100\n",
      "4225/4225 [==============================] - 1s 147us/sample - loss: 0.5665 - acc: 0.7993\n",
      "Epoch 47/100\n",
      "4225/4225 [==============================] - 1s 154us/sample - loss: 0.5498 - acc: 0.7934\n",
      "Epoch 48/100\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.5296 - acc: 0.7929\n",
      "Epoch 49/100\n",
      "4225/4225 [==============================] - 1s 144us/sample - loss: 0.5383 - acc: 0.7877\n",
      "Epoch 50/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 0.5578 - acc: 0.8031\n",
      "Epoch 51/100\n",
      "4225/4225 [==============================] - 1s 147us/sample - loss: 0.5502 - acc: 0.7976\n",
      "Epoch 52/100\n",
      "4225/4225 [==============================] - 1s 154us/sample - loss: 0.5323 - acc: 0.7964\n",
      "Epoch 53/100\n",
      "4225/4225 [==============================] - 1s 167us/sample - loss: 0.6029 - acc: 0.7960\n",
      "Epoch 54/100\n",
      "4225/4225 [==============================] - 1s 149us/sample - loss: 0.5821 - acc: 0.7908\n",
      "Epoch 55/100\n",
      "4225/4225 [==============================] - 1s 127us/sample - loss: 0.5872 - acc: 0.7953\n",
      "Epoch 56/100\n",
      "4225/4225 [==============================] - 0s 114us/sample - loss: 0.5932 - acc: 0.7957\n",
      "Epoch 57/100\n",
      "4225/4225 [==============================] - 1s 124us/sample - loss: 0.6292 - acc: 0.7986\n",
      "Epoch 58/100\n",
      "4225/4225 [==============================] - 0s 116us/sample - loss: 0.5225 - acc: 0.7960\n",
      "Epoch 59/100\n",
      "4225/4225 [==============================] - 0s 113us/sample - loss: 0.5104 - acc: 0.8012\n",
      "Epoch 60/100\n",
      "4225/4225 [==============================] - 0s 118us/sample - loss: 0.5380 - acc: 0.7983\n",
      "Epoch 61/100\n",
      "4225/4225 [==============================] - 0s 116us/sample - loss: 0.5808 - acc: 0.7948\n",
      "Epoch 62/100\n",
      "4225/4225 [==============================] - 1s 141us/sample - loss: 0.5014 - acc: 0.7969\n",
      "Epoch 63/100\n",
      "4225/4225 [==============================] - 1s 146us/sample - loss: 0.5248 - acc: 0.7964\n",
      "Epoch 64/100\n",
      "4225/4225 [==============================] - 1s 123us/sample - loss: 0.5407 - acc: 0.7983\n",
      "Epoch 65/100\n",
      "4225/4225 [==============================] - 1s 127us/sample - loss: 0.5252 - acc: 0.7915\n",
      "Epoch 66/100\n",
      "4225/4225 [==============================] - 0s 115us/sample - loss: 0.5675 - acc: 0.8040\n",
      "Epoch 67/100\n",
      "4225/4225 [==============================] - 1s 120us/sample - loss: 0.5766 - acc: 0.8040\n",
      "Epoch 68/100\n",
      "4225/4225 [==============================] - 0s 114us/sample - loss: 0.5283 - acc: 0.7931\n",
      "Epoch 69/100\n",
      "4225/4225 [==============================] - 1s 136us/sample - loss: 0.5043 - acc: 0.8002\n",
      "Epoch 70/100\n",
      "4225/4225 [==============================] - 1s 154us/sample - loss: 0.5317 - acc: 0.8017\n",
      "Epoch 71/100\n",
      "4225/4225 [==============================] - 1s 132us/sample - loss: 0.5231 - acc: 0.8000\n",
      "Epoch 72/100\n",
      "4225/4225 [==============================] - 1s 141us/sample - loss: 0.5076 - acc: 0.7950\n",
      "Epoch 73/100\n",
      "4225/4225 [==============================] - 1s 143us/sample - loss: 0.5108 - acc: 0.7972\n",
      "Epoch 74/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.5323 - acc: 0.8000\n",
      "Epoch 75/100\n",
      "4225/4225 [==============================] - 1s 151us/sample - loss: 0.5338 - acc: 0.7967\n",
      "Epoch 76/100\n",
      "4225/4225 [==============================] - 0s 117us/sample - loss: 0.5295 - acc: 0.7955\n",
      "Epoch 77/100\n",
      "4225/4225 [==============================] - 1s 125us/sample - loss: 0.5405 - acc: 0.8005\n",
      "Epoch 78/100\n",
      "4225/4225 [==============================] - 0s 116us/sample - loss: 0.5471 - acc: 0.8000\n",
      "Epoch 79/100\n",
      "4225/4225 [==============================] - 1s 134us/sample - loss: 0.5286 - acc: 0.8007\n",
      "Epoch 80/100\n",
      "4225/4225 [==============================] - 1s 131us/sample - loss: 0.5419 - acc: 0.7986\n",
      "Epoch 81/100\n",
      "4225/4225 [==============================] - 1s 144us/sample - loss: 0.5364 - acc: 0.8007\n",
      "Epoch 82/100\n",
      "4225/4225 [==============================] - 1s 164us/sample - loss: 0.5937 - acc: 0.7983\n",
      "Epoch 83/100\n",
      "4225/4225 [==============================] - 1s 134us/sample - loss: 0.5643 - acc: 0.8000\n",
      "Epoch 84/100\n",
      "4225/4225 [==============================] - 1s 135us/sample - loss: 0.5364 - acc: 0.7981\n",
      "Epoch 85/100\n",
      "4225/4225 [==============================] - 1s 140us/sample - loss: 0.5859 - acc: 0.8017\n",
      "Epoch 86/100\n",
      "4225/4225 [==============================] - 1s 120us/sample - loss: 0.5019 - acc: 0.8009\n",
      "Epoch 87/100\n",
      "4225/4225 [==============================] - 1s 142us/sample - loss: 0.5577 - acc: 0.7957\n",
      "Epoch 88/100\n",
      "4225/4225 [==============================] - 1s 156us/sample - loss: 0.5467 - acc: 0.8012\n",
      "Epoch 89/100\n",
      "4225/4225 [==============================] - 1s 195us/sample - loss: 0.5337 - acc: 0.8002\n",
      "Epoch 90/100\n",
      "4225/4225 [==============================] - 1s 182us/sample - loss: 0.5564 - acc: 0.7974\n",
      "Epoch 91/100\n",
      "4225/4225 [==============================] - 1s 174us/sample - loss: 0.5327 - acc: 0.7972\n",
      "Epoch 92/100\n",
      "4225/4225 [==============================] - 1s 169us/sample - loss: 0.6157 - acc: 0.7979\n",
      "Epoch 93/100\n",
      "4225/4225 [==============================] - 1s 182us/sample - loss: 0.5764 - acc: 0.7934s - loss: 0.5150 -\n",
      "Epoch 94/100\n",
      "4225/4225 [==============================] - 1s 148us/sample - loss: 0.6129 - acc: 0.8007\n",
      "Epoch 95/100\n",
      "4225/4225 [==============================] - 1s 185us/sample - loss: 0.5606 - acc: 0.7962\n",
      "Epoch 96/100\n",
      "4225/4225 [==============================] - 1s 182us/sample - loss: 0.5451 - acc: 0.8005\n",
      "Epoch 97/100\n",
      "4225/4225 [==============================] - 1s 166us/sample - loss: 0.5258 - acc: 0.8021\n",
      "Epoch 98/100\n",
      "4225/4225 [==============================] - 1s 197us/sample - loss: 0.5515 - acc: 0.7983\n",
      "Epoch 99/100\n",
      "4225/4225 [==============================] - 1s 168us/sample - loss: 0.5314 - acc: 0.8005\n",
      "Epoch 100/100\n",
      "4225/4225 [==============================] - 1s 172us/sample - loss: 0.5642 - acc: 0.7953\n",
      "2818/2818 [==============================] - 0s 126us/sample - loss: 0.5643 - acc: 0.8091\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, input_dim=43, activation='sigmoid'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='sigmoid'))\n",
    "#model.add(layers.Dense(64, activation='sigmoid'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "#sgd = tf.keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              #optimizer = tf.train.AdamOptimizer(0.001),\n",
    "              optimizer='rmsprop',\n",
    "              #optimizer = sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=100,\n",
    "          batch_size=32)\n",
    "score = model.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model, we determined a patience of 10 epochs. The model performed almost equally to compared to Experiment's 1 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "* First layer with 43 input features combined with a dropout layer.\n",
    "* Second layer with 64 neurons combined with a dropout layer.\n",
    "* Output layer with sigmoid activation \n",
    "* Stochastic Gradient Descent as optimizer using NAG. \n",
    "* cross entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_3 = [EarlyStopping(monitor='val_acc', patience=10),\n",
    "             ModelCheckpoint(('mlp/experiment_3/model.h5'), save_best_only=True, \n",
    "                             save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4225 samples, validate on 1409 samples\n",
      "Epoch 1/100\n",
      "4225/4225 [==============================] - 2s 557us/sample - loss: 10.5947 - acc: 0.3037 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 2/100\n",
      "4225/4225 [==============================] - 1s 294us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 3/100\n",
      "4225/4225 [==============================] - 1s 280us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 4/100\n",
      "4225/4225 [==============================] - 1s 248us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 5/100\n",
      "4225/4225 [==============================] - 1s 280us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 6/100\n",
      "4225/4225 [==============================] - 1s 213us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 7/100\n",
      "4225/4225 [==============================] - 1s 264us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 8/100\n",
      "4225/4225 [==============================] - 1s 271us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 9/100\n",
      "4225/4225 [==============================] - 1s 291us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 10/100\n",
      "4225/4225 [==============================] - 1s 256us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "Epoch 11/100\n",
      "4225/4225 [==============================] - 1s 278us/sample - loss: 11.2649 - acc: 0.2653 - val_loss: 11.2632 - val_acc: 0.2654\n",
      "1409/1409 [==============================] - 0s 101us/sample - loss: 11.2632 - acc: 0.2654\n"
     ]
    }
   ],
   "source": [
    "model_3 = tf.keras.Sequential()\n",
    "model_3.add(layers.Dense(64, input_dim=43, activation='sigmoid'))\n",
    "model_3.add(layers.Dropout(0.5))\n",
    "model_3.add(layers.Dense(64, activation='sigmoid'))\n",
    "model_3.add(layers.Dropout(0.5))\n",
    "model_3.add(layers.Dense(1, activation='linear'))\n",
    "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_3.compile(loss='binary_crossentropy',\n",
    "              optimizer = sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "model_3.fit(X_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size, callbacks = callbacks_3, validation_data =(X_validation, y_validation))\n",
    "score_3 = model_3.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SGD as an optimizer result in poor results. SGD is known to have a high variance in error due to the fact that each observation is fed individually. Training time took longer than the previous experiments.\n",
    "\n",
    "This model was tested with several learning rates and the results did not improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4\n",
    "* First layer with 43 input features combined with a dropout layer.\n",
    "* Second layer with 64 neurons combined with a dropout layer.\n",
    "* Output layer with 128 neurons. \n",
    "* Output layer with sigmoid activation \n",
    "* Adam Optimizer.\n",
    "* cross entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_4 = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(('mlp/experiment_4/model.h5'), save_best_only=True, \n",
    "                             save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = tf.keras.Sequential()\n",
    "model_4.add(layers.Dense(64, input_dim=43, activation='sigmoid'))\n",
    "model_4.add(layers.Dropout(0.5))\n",
    "model_4.add(layers.Dense(128, activation='relu'))\n",
    "model_4.add(layers.Dropout(0.5))\n",
    "model_4.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_4.compile(loss='binary_crossentropy',\n",
    "              optimizer = tf.train.AdamOptimizer(0.001),\n",
    "              #optimizer='rmsprop',\n",
    "              #optimizer = sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4225 samples, validate on 1409 samples\n",
      "Epoch 1/100\n",
      "4225/4225 [==============================] - 1s 137us/sample - loss: 0.6106 - acc: 0.7039 - val_loss: 0.5082 - val_acc: 0.7608\n",
      "Epoch 2/100\n",
      "4225/4225 [==============================] - 0s 23us/sample - loss: 0.5548 - acc: 0.7401 - val_loss: 0.4913 - val_acc: 0.7722\n",
      "Epoch 3/100\n",
      "4225/4225 [==============================] - 0s 21us/sample - loss: 0.5258 - acc: 0.7564 - val_loss: 0.4899 - val_acc: 0.7800\n",
      "Epoch 4/100\n",
      "4225/4225 [==============================] - 0s 25us/sample - loss: 0.5135 - acc: 0.7640 - val_loss: 0.4796 - val_acc: 0.7835\n",
      "Epoch 5/100\n",
      "4225/4225 [==============================] - 0s 23us/sample - loss: 0.5106 - acc: 0.7652 - val_loss: 0.4718 - val_acc: 0.7885\n",
      "Epoch 6/100\n",
      "4225/4225 [==============================] - 0s 26us/sample - loss: 0.4930 - acc: 0.7707 - val_loss: 0.4632 - val_acc: 0.7906\n",
      "Epoch 7/100\n",
      "4225/4225 [==============================] - 0s 27us/sample - loss: 0.4888 - acc: 0.7657 - val_loss: 0.4525 - val_acc: 0.7935\n",
      "Epoch 8/100\n",
      "4225/4225 [==============================] - 0s 27us/sample - loss: 0.4821 - acc: 0.7702 - val_loss: 0.4485 - val_acc: 0.7956\n",
      "Epoch 9/100\n",
      "4225/4225 [==============================] - 0s 23us/sample - loss: 0.4697 - acc: 0.7775 - val_loss: 0.4452 - val_acc: 0.7949\n",
      "Epoch 10/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4683 - acc: 0.7749 - val_loss: 0.4366 - val_acc: 0.8041\n",
      "Epoch 11/100\n",
      "4225/4225 [==============================] - 0s 23us/sample - loss: 0.4642 - acc: 0.7830 - val_loss: 0.4346 - val_acc: 0.7999\n",
      "Epoch 12/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4557 - acc: 0.7856 - val_loss: 0.4288 - val_acc: 0.8041\n",
      "Epoch 13/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4523 - acc: 0.7910 - val_loss: 0.4370 - val_acc: 0.7956\n",
      "Epoch 14/100\n",
      "4225/4225 [==============================] - 0s 23us/sample - loss: 0.4524 - acc: 0.7867 - val_loss: 0.4269 - val_acc: 0.8041\n",
      "Epoch 15/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4542 - acc: 0.7832 - val_loss: 0.4279 - val_acc: 0.8034\n",
      "Epoch 16/100\n",
      "4225/4225 [==============================] - 0s 26us/sample - loss: 0.4507 - acc: 0.7858 - val_loss: 0.4318 - val_acc: 0.8027\n",
      "Epoch 17/100\n",
      "4225/4225 [==============================] - 0s 37us/sample - loss: 0.4525 - acc: 0.7822 - val_loss: 0.4257 - val_acc: 0.8041\n",
      "Epoch 18/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4429 - acc: 0.7936 - val_loss: 0.4245 - val_acc: 0.8062\n",
      "Epoch 19/100\n",
      "4225/4225 [==============================] - 0s 26us/sample - loss: 0.4445 - acc: 0.7830 - val_loss: 0.4228 - val_acc: 0.8126\n",
      "Epoch 20/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4440 - acc: 0.7934 - val_loss: 0.4245 - val_acc: 0.8041\n",
      "Epoch 21/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4440 - acc: 0.7872 - val_loss: 0.4221 - val_acc: 0.8098\n",
      "Epoch 22/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4490 - acc: 0.7879 - val_loss: 0.4278 - val_acc: 0.8105\n",
      "Epoch 23/100\n",
      "4225/4225 [==============================] - 0s 24us/sample - loss: 0.4428 - acc: 0.7884 - val_loss: 0.4240 - val_acc: 0.8119\n",
      "Epoch 24/100\n",
      "4225/4225 [==============================] - 0s 22us/sample - loss: 0.4376 - acc: 0.7905 - val_loss: 0.4199 - val_acc: 0.8112\n",
      "Epoch 25/100\n",
      "4225/4225 [==============================] - 0s 25us/sample - loss: 0.4385 - acc: 0.7908 - val_loss: 0.4208 - val_acc: 0.8112\n",
      "Epoch 26/100\n",
      "4225/4225 [==============================] - 0s 29us/sample - loss: 0.4372 - acc: 0.7943 - val_loss: 0.4226 - val_acc: 0.8112\n",
      "Epoch 27/100\n",
      "4225/4225 [==============================] - 0s 25us/sample - loss: 0.4366 - acc: 0.7974 - val_loss: 0.4209 - val_acc: 0.8133\n",
      "Epoch 28/100\n",
      "4225/4225 [==============================] - 0s 25us/sample - loss: 0.4354 - acc: 0.7967 - val_loss: 0.4216 - val_acc: 0.8119\n",
      "Epoch 29/100\n",
      "4225/4225 [==============================] - 0s 26us/sample - loss: 0.4363 - acc: 0.7920 - val_loss: 0.4203 - val_acc: 0.8119\n",
      "1409/1409 [==============================] - 0s 16us/sample - loss: 0.4203 - acc: 0.8119\n"
     ]
    }
   ],
   "source": [
    "model_4.fit(X_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size, callbacks=callbacks_4, validation_data=(X_test,y_test))\n",
    "score_4 = model_4.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural net was more complex than the ones created on previous experiments, as it had twice the amount of neurons in one layer than previous implementations. Accuracy for the test set improved by 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5 \n",
    "\n",
    "The objective of this experiment is to create a complex and biased neural network that will perform exceptionally on the training set but poorly on the testing set. Previous architectures where not able to improve accuracy over 0.82.\n",
    "\n",
    "* First layer with 43 input features combined with a dropout layer.\n",
    "* Second,third, and fifth  layer with 128 neurons combined with a dropout layer.\n",
    "* Fourth layer with 256 neurons.\n",
    "* Output layer with sigmoid activation \n",
    "* Adam optimizer\n",
    "* cross entropy as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_5 = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(('mlp/experiment_5/model.h5'), save_best_only=True, \n",
    "                             save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = tf.keras.Sequential()\n",
    "model_5.add(layers.Dense(64, input_dim=43, activation='sigmoid'))\n",
    "model_5.add(layers.Dropout(0.5))\n",
    "model_5.add(layers.Dense(128, activation='relu'))\n",
    "model_5.add(layers.Dropout(0.5))\n",
    "model_5.add(layers.Dense(128, activation='sigmoid'))\n",
    "model_5.add(layers.Dense(256, activation='tanh'))\n",
    "model_5.add(layers.Dense(128, activation='sigmoid'))\n",
    "model_5.add(layers.Dropout(0.5))\n",
    "model_5.add(layers.Dense(1, activation='sigmoid'))\n",
    "model_5.compile(loss='binary_crossentropy',\n",
    "              optimizer = tf.train.AdamOptimizer(0.001),\n",
    "              #optimizer='rmsprop',\n",
    "              #optimizer = sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4225 samples, validate on 1409 samples\n",
      "Epoch 1/100\n",
      "2304/4225 [===============>..............] - ETA: 0s - loss: 0.7116 - acc: 0.6480WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 2s 368us/sample - loss: 0.6681 - acc: 0.6788 - val_loss: 0.5834 - val_acc: 0.7346\n",
      "Epoch 2/100\n",
      "2304/4225 [===============>..............] - ETA: 0s - loss: 0.6047 - acc: 0.7109WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 1s 134us/sample - loss: 0.6127 - acc: 0.7157 - val_loss: 0.5610 - val_acc: 0.7346\n",
      "Epoch 3/100\n",
      "3584/4225 [========================>.....] - ETA: 0s - loss: 0.5885 - acc: 0.7185WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 59us/sample - loss: 0.5793 - acc: 0.7259 - val_loss: 0.5240 - val_acc: 0.7346\n",
      "Epoch 4/100\n",
      "3840/4225 [==========================>...] - ETA: 0s - loss: 0.5289 - acc: 0.7521WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 80us/sample - loss: 0.5259 - acc: 0.7548 - val_loss: 0.4783 - val_acc: 0.7715\n",
      "Epoch 5/100\n",
      "3584/4225 [========================>.....] - ETA: 0s - loss: 0.5077 - acc: 0.7614WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 83us/sample - loss: 0.5050 - acc: 0.7633 - val_loss: 0.4591 - val_acc: 0.7892\n",
      "Epoch 6/100\n",
      "2304/4225 [===============>..............] - ETA: 0s - loss: 0.5124 - acc: 0.7517WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 87us/sample - loss: 0.4953 - acc: 0.7609 - val_loss: 0.4448 - val_acc: 0.7913\n",
      "Epoch 7/100\n",
      "2304/4225 [===============>..............] - ETA: 0s - loss: 0.4821 - acc: 0.7700WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 71us/sample - loss: 0.4804 - acc: 0.7673 - val_loss: 0.4364 - val_acc: 0.7878\n",
      "Epoch 8/100\n",
      "3840/4225 [==========================>...] - ETA: 0s - loss: 0.4625 - acc: 0.7786WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 1s 122us/sample - loss: 0.4635 - acc: 0.7763 - val_loss: 0.4306 - val_acc: 0.7942\n",
      "Epoch 9/100\n",
      "4225/4225 [==============================] - 0s 36us/sample - loss: 0.4681 - acc: 0.7744 - val_loss: 0.4318 - val_acc: 0.7956\n",
      "Epoch 10/100\n",
      "4225/4225 [==============================] - 0s 32us/sample - loss: 0.4604 - acc: 0.7761 - val_loss: 0.4365 - val_acc: 0.7807\n",
      "Epoch 11/100\n",
      "3584/4225 [========================>.....] - ETA: 0s - loss: 0.4506 - acc: 0.7863WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 1s 332us/sample - loss: 0.4550 - acc: 0.7834 - val_loss: 0.4251 - val_acc: 0.7977\n",
      "Epoch 12/100\n",
      "4096/4225 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.7847WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 80us/sample - loss: 0.4560 - acc: 0.7834 - val_loss: 0.4233 - val_acc: 0.8013\n",
      "Epoch 13/100\n",
      "3328/4225 [======================>.......] - ETA: 0s - loss: 0.4508 - acc: 0.7831WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 87us/sample - loss: 0.4513 - acc: 0.7851 - val_loss: 0.4187 - val_acc: 0.8027\n",
      "Epoch 14/100\n",
      "4225/4225 [==============================] - 0s 40us/sample - loss: 0.4484 - acc: 0.7822 - val_loss: 0.4190 - val_acc: 0.8027\n",
      "Epoch 15/100\n",
      "4225/4225 [==============================] - 0s 44us/sample - loss: 0.4514 - acc: 0.7856 - val_loss: 0.4189 - val_acc: 0.8034\n",
      "Epoch 16/100\n",
      "4225/4225 [==============================] - 0s 41us/sample - loss: 0.4488 - acc: 0.7870 - val_loss: 0.4205 - val_acc: 0.8006\n",
      "Epoch 17/100\n",
      "4096/4225 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.7852WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 78us/sample - loss: 0.4480 - acc: 0.7844 - val_loss: 0.4174 - val_acc: 0.8062\n",
      "Epoch 18/100\n",
      "3328/4225 [======================>.......] - ETA: 0s - loss: 0.4388 - acc: 0.7882WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 86us/sample - loss: 0.4403 - acc: 0.7875 - val_loss: 0.4149 - val_acc: 0.7991\n",
      "Epoch 19/100\n",
      "4225/4225 [==============================] - 0s 38us/sample - loss: 0.4491 - acc: 0.7912 - val_loss: 0.4163 - val_acc: 0.8098\n",
      "Epoch 20/100\n",
      "3584/4225 [========================>.....] - ETA: 0s - loss: 0.4506 - acc: 0.7762WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 1s 266us/sample - loss: 0.4490 - acc: 0.7792 - val_loss: 0.4147 - val_acc: 0.8105\n",
      "Epoch 21/100\n",
      "4225/4225 [==============================] - 0s 30us/sample - loss: 0.4417 - acc: 0.7872 - val_loss: 0.4161 - val_acc: 0.8020\n",
      "Epoch 22/100\n",
      "4225/4225 [==============================] - 0s 31us/sample - loss: 0.4428 - acc: 0.7889 - val_loss: 0.4195 - val_acc: 0.8119\n",
      "Epoch 23/100\n",
      "4225/4225 [==============================] - 0s 31us/sample - loss: 0.4417 - acc: 0.7822 - val_loss: 0.4227 - val_acc: 0.7949\n",
      "Epoch 24/100\n",
      "4225/4225 [==============================] - 0s 41us/sample - loss: 0.4407 - acc: 0.7910 - val_loss: 0.4190 - val_acc: 0.8041\n",
      "Epoch 25/100\n",
      "3072/4225 [====================>.........] - ETA: 0s - loss: 0.4322 - acc: 0.7917WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 1s 176us/sample - loss: 0.4364 - acc: 0.7922 - val_loss: 0.4136 - val_acc: 0.8098\n",
      "Epoch 26/100\n",
      "4225/4225 [==============================] - 0s 36us/sample - loss: 0.4349 - acc: 0.7917 - val_loss: 0.4142 - val_acc: 0.8041\n",
      "Epoch 27/100\n",
      "4225/4225 [==============================] - 0s 42us/sample - loss: 0.4325 - acc: 0.7995 - val_loss: 0.4184 - val_acc: 0.8070\n",
      "Epoch 28/100\n",
      "4225/4225 [==============================] - 0s 34us/sample - loss: 0.4358 - acc: 0.7893 - val_loss: 0.4172 - val_acc: 0.8062\n",
      "Epoch 29/100\n",
      "4225/4225 [==============================] - 0s 37us/sample - loss: 0.4360 - acc: 0.7891 - val_loss: 0.4143 - val_acc: 0.8077\n",
      "Epoch 30/100\n",
      "4096/4225 [============================>.] - ETA: 0s - loss: 0.4360 - acc: 0.7893WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 72us/sample - loss: 0.4338 - acc: 0.7920 - val_loss: 0.4134 - val_acc: 0.8105\n",
      "Epoch 31/100\n",
      "4225/4225 [==============================] - 0s 34us/sample - loss: 0.4365 - acc: 0.7927 - val_loss: 0.4136 - val_acc: 0.8133\n",
      "Epoch 32/100\n",
      "4225/4225 [==============================] - 0s 44us/sample - loss: 0.4355 - acc: 0.7983 - val_loss: 0.4237 - val_acc: 0.8020\n",
      "Epoch 33/100\n",
      "4225/4225 [==============================] - 0s 44us/sample - loss: 0.4361 - acc: 0.7960 - val_loss: 0.4157 - val_acc: 0.8020\n",
      "Epoch 34/100\n",
      "3584/4225 [========================>.....] - ETA: 0s - loss: 0.4316 - acc: 0.7958WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "4225/4225 [==============================] - 0s 72us/sample - loss: 0.4313 - acc: 0.7946 - val_loss: 0.4131 - val_acc: 0.8119\n",
      "Epoch 35/100\n",
      "4225/4225 [==============================] - 0s 34us/sample - loss: 0.4320 - acc: 0.7953 - val_loss: 0.4135 - val_acc: 0.8055\n",
      "Epoch 36/100\n",
      "4225/4225 [==============================] - 0s 31us/sample - loss: 0.4334 - acc: 0.7924 - val_loss: 0.4146 - val_acc: 0.8027\n",
      "Epoch 37/100\n",
      "4225/4225 [==============================] - 0s 52us/sample - loss: 0.4350 - acc: 0.7912 - val_loss: 0.4143 - val_acc: 0.8098\n",
      "Epoch 38/100\n",
      "4225/4225 [==============================] - 0s 43us/sample - loss: 0.4256 - acc: 0.8019 - val_loss: 0.4133 - val_acc: 0.8112\n",
      "Epoch 39/100\n",
      "4225/4225 [==============================] - 0s 44us/sample - loss: 0.4327 - acc: 0.7941 - val_loss: 0.4177 - val_acc: 0.7977\n",
      "1409/1409 [==============================] - 0s 22us/sample - loss: 0.4177 - acc: 0.7977\n"
     ]
    }
   ],
   "source": [
    "model_5.fit(X_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size, callbacks=callbacks_5, validation_data=(X_test,y_test))\n",
    "score_5 = model_5.evaluate(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, this model performed poorly compared to previous experiments even though it was more complex. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions \n",
    "\n",
    "Several neural networks where implemented for this dataset. Experiment 1 and 2 performed almost equally. Experiment 3 performed poorly due to the use of SGD as an optimizer. Experiment 4 had the best accuracy and is, overall the best model. Experiment 5 performed poorly considering that it was the most complex. This shows the importance of choosing the correct architecture to avoid underfitting and overfitting when making inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
